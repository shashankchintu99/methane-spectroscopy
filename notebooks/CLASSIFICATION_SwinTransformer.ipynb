{"cells":[{"cell_type":"markdown","metadata":{"id":"OdeM29wVS6io"},"source":["Hello fellow Kagglers,\n","\n","This notebook is a first draft for this competition and is shared to get people started.\n","\n","* V1 Shows the training process\n","* V2 Uses the precomputed DataFrames and pretrained model to make the inference\n","* V3 More plots and filtering data based on sample submission min/max\n","* V5 Excluding samples based on 0.1%< or >99.9% of train samples since sample submission is updated. Thanks to [Myrthe deen](https://www.kaggle.com/myrthedeen) for pointing this out."]},{"cell_type":"markdown","metadata":{"id":"EMZRJTOIS6ip"},"source":["# Imports"]},{"cell_type":"markdown","metadata":{"id":"eNOS1NvnS6ip"},"source":["pip install numpy pandas matplotlib imageio albumentations torch torchmetrics scikit-learn torchvision timm tqdm\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zmi1OvpAS_cZ","executionInfo":{"status":"ok","timestamp":1715596519767,"user_tz":420,"elapsed":935,"user":{"displayName":"john","userId":"07467961182254583902"}},"outputId":"879d3ea9-b603-4cc5-9071-105146cebd03"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["print(os.listdir('/content/drive/MyDrive/planttraits2024'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1ju0GMKiFAC","executionInfo":{"status":"ok","timestamp":1715596712702,"user_tz":420,"elapsed":129,"user":{"displayName":"john","userId":"07467961182254583902"}},"outputId":"a3bbc42c-395c-4e59-e86d-ea0f0f24341b"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["['sample_submission.csv', 'target_name_meta.tsv', 'test.csv', 'test_images', 'train.csv', 'train_images']\n"]}]},{"cell_type":"code","source":["pip install timm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-DdIkPxTZ2A","executionInfo":{"status":"ok","timestamp":1715594074687,"user_tz":420,"elapsed":5150,"user":{"displayName":"john","userId":"07467961182254583902"}},"outputId":"c194cae0-ca96-40eb-c61e-b666ba125c98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.16)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.2.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.1+cu121)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.11.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.4.127)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n"]}]},{"cell_type":"code","source":["pip install torchmetrics\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9irUzwg_T4zu","executionInfo":{"status":"ok","timestamp":1715594080661,"user_tz":420,"elapsed":6003,"user":{"displayName":"john","userId":"07467961182254583902"}},"outputId":"42d70fc2-decc-4613-d4b6-fcdc55080011"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.4.0)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.2)\n","Requirement already satisfied: pretty-errors==1.2.25 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.2.25)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from pretty-errors==1.2.25->torchmetrics) (0.4.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.14.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"]}]},{"cell_type":"code","execution_count":17,"metadata":{"id":"8Hem-UVcS6iq","executionInfo":{"status":"ok","timestamp":1715596526234,"user_tz":420,"elapsed":131,"user":{"displayName":"john","userId":"07467961182254583902"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import imageio.v3 as  imageio\n","import albumentations as A\n","\n","from albumentations.pytorch import ToTensorV2\n","from torch.utils.data import Dataset, DataLoader\n","from torch import nn\n","from tqdm.notebook import tqdm\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from torchvision import transforms\n","\n","import torch\n","import timm\n","import glob\n","import torchmetrics\n","import time\n","import psutil\n","import os\n","import math\n","import warnings\n","\n","tqdm.pandas()"]},{"cell_type":"markdown","metadata":{"id":"bJX2Y4BWS6iq"},"source":["# Config"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"RChMCKu7S6iq","executionInfo":{"status":"ok","timestamp":1715596530180,"user_tz":420,"elapsed":200,"user":{"displayName":"john","userId":"07467961182254583902"}}},"outputs":[],"source":["class Config():\n","    IMAGE_SIZE0 = 512\n","    IMAGE_SIZE = 288\n","    TARGET_COLUMNS = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n","    TARGET_COLUMNS_TEST = ['X4', 'X11', 'X18', 'X50', 'X26', 'X3112']\n","    N_TARGETS = len(TARGET_COLUMNS)\n","    # Dataset\n","    RECOMPUTE_DATAFRAMES = True\n","    BATCH_SIZE = 24\n","    BATCH_SIZE_VAL = 128\n","    N_VAL_SAMPLES0 = 4096\n","    # Training\n","    LR_MAX = 3e-4\n","    WEIGHT_DECAY = 0.01\n","    N_EPOCHS = 12\n","    TRAIN_MODEL = True\n","    # Others\n","    IS_INTERACTIVE = False\n","    SEED = 42\n","    EPS = 1e-6\n","\n","CONFIG = Config()"]},{"cell_type":"markdown","metadata":{"id":"4av1lwc3S6iq"},"source":["# Train DataFrame"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gBuHuEQVS6iq","executionInfo":{"status":"ok","timestamp":1715594092652,"user_tz":420,"elapsed":6435,"user":{"displayName":"john","userId":"07467961182254583902"}},"outputId":"53f9858f-88de-4af6-8470-f2e703497773"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: jupyter in /usr/local/lib/python3.10/dist-packages (1.0.0)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (8.1.2)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter) (6.5.5)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.10/dist-packages (from jupyter) (5.5.2)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter) (6.1.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter) (6.5.4)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter) (5.5.6)\n","Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.2)\n","Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n","Requirement already satisfied: widgetsnbextension~=4.0.10 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (4.0.10)\n","Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.10)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (67.7.2)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (0.2.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (6.3.3)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (4.9.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (4.12.3)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (6.1.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.7.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.4)\n","Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (3.1.4)\n","Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (5.7.2)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (2.1.5)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.8.4)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.10.0)\n","Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (5.10.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (24.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (1.3.0)\n","Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (24.0.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (23.1.0)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (1.6.0)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (0.20.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (1.0.0)\n","Requirement already satisfied: qtpy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from qtconsole->jupyter) (2.4.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->jupyter) (2.8.2)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter) (4.2.1)\n","Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter) (1.24.0)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter) (0.2.4)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter) (2.19.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter) (4.19.2)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter) (21.2.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter) (2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter) (1.16.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter) (0.5.1)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter) (0.18.1)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.8.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (1.16.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (3.7)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.2.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.22)\n"]}],"source":["pip install --upgrade jupyter ipywidgets\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"nL5oTleLS6ir","executionInfo":{"status":"ok","timestamp":1715596866699,"user_tz":420,"elapsed":121,"user":{"displayName":"john","userId":"07467961182254583902"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import os\n","train_data_path = '/content/drive/MyDrive/planttraits2024/train.csv'\n","test_data_path = '/content/drive/MyDrive/planttraits2024/test.csv'\n","train_images_path = '/content/drive/MyDrive/planttraits2024/train_images'\n","test_images_path = '/content/drive/MyDrive/planttraits2024/test_images'"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"4GMRKrv4S6ir","executionInfo":{"status":"error","timestamp":1715596944557,"user_tz":420,"elapsed":1796,"user":{"displayName":"john","userId":"07467961182254583902"}},"colab":{"base_uri":"https://localhost:8080/","height":418,"referenced_widgets":["f39a07b5909349078ef9f32b62603973","f6dc36e4f7524cbc9fcf7f0e65bec227","1485ddcecf2f4aacb026b0def6901589","deafdc1b0cfc43ef9807cd48e64aa524","1430c059eb1c459bb7a3cbd7e21bd2b3","5f1e37e804cb4ad8ae7e606fd0b6f55c","c98318f60963493f86286e7e42f427c6","ec8a33b0aefd4b509545460098351058","d6f0f33b02b6477099b1944b8ec998e3","bba9ab2a59884be887fc8c187864e1f2","c1e3168f3e884f95b10d924236222e50"]},"outputId":"385121fe-28de-4c9c-a563-bc1c1edfaeb1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/55489 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f39a07b5909349078ef9f32b62603973"}},"metadata":{}},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/planttraits2024train_images/192027691.jpeg'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-e6c9352e1e37>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Reaed Raw Image JPEG Bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jpeg_bytes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Save for Future Use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4628\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4629\u001b[0m         \"\"\"\n\u001b[0;32m-> 4630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m     def _reduce(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1077\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-e6c9352e1e37>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fp)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Reaed Raw Image JPEG Bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jpeg_bytes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Save for Future Use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/planttraits2024train_images/192027691.jpeg'"]}],"source":["if CONFIG.RECOMPUTE_DATAFRAMES:\n","    train0 = pd.read_csv(train_data_path)\n","\n","    # Add File Path\n","    train0['file_path'] = train0['id'].apply(lambda s: f'/content/drive/MyDrive/planttraits2024train_images/{s}.jpeg')\n","\n","    # Reaed Raw Image JPEG Bytes\n","    train0['jpeg_bytes'] = train0['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\n","\n","    # Save for Future Use\n","    train0.to_pickle('/content/drive/MyDrive/planttraits2024/train.pkl')\n","else:\n","    train0 = pd.read_pickle('/content/drive/MyDrive/planttraits2024/train.pkl')\n","\n","# Assign Medians\n","CONFIG.TARGET_MEDIANS = train0[CONFIG.TARGET_COLUMNS].median(axis=0).values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zEr6w0qAS6ir"},"outputs":[],"source":["# Split train in train/val\n","train, val = train_test_split(train0, test_size=CONFIG.N_VAL_SAMPLES0, shuffle=True, random_state=CONFIG.SEED)\n","\n","train = train.reset_index(drop=True)\n","val = val.reset_index(drop=True)\n","\n","# Display DataFrame\n","display(train.head(30))\n","display(train.info())"]},{"cell_type":"markdown","metadata":{"id":"ZjdSnf6vS6ir"},"source":["# Test DataFrame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NTK8uEgES6ir"},"outputs":[],"source":["if CONFIG.RECOMPUTE_DATAFRAMES:\n","    test = pd.read_csv(test_data_path)\n","\n","    # Add File Path\n","    test['file_path'] = test['id'].apply(lambda s: f'planttraits2024/test_images/{s}.jpeg')\n","\n","    # Reaed Raw Image JPEG Bytes\n","    test['jpeg_bytes'] = test['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\n","\n","    # Save for Future Use\n","    test.to_pickle('planttraits2024/test.pkl')\n","else:\n","    test = pd.read_pickle('/content/drive/MyDrive/test.pkl')\n","\n","display(test.head())\n","display(test.info())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bH0yQ68pS6ir"},"outputs":[],"source":["# Feature Columns\n","FEATURE_COLUMNS = test.columns.values[1:-2]\n","CONFIG.N_FEATURES = len(FEATURE_COLUMNS)\n","print(f'N_FEATURES: {CONFIG.N_FEATURES}')"]},{"cell_type":"markdown","metadata":{"id":"XOBHaJcKS6ir"},"source":["# Sample Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7GyAHXAIS6ir"},"outputs":[],"source":["train[CONFIG.TARGET_COLUMNS].quantile(0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"94ejhgvZS6ir"},"outputs":[],"source":["sample_submission = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')\n","\n","# Minimum/Maximum Based On Train 0.1% and 99.9%\n","CONFIG.V_MIN = train[CONFIG.TARGET_COLUMNS].quantile(0.001)\n","CONFIG.V_MAX = train[CONFIG.TARGET_COLUMNS].quantile(0.999)\n","\n","display(sample_submission.head())\n","display(sample_submission.info())"]},{"cell_type":"markdown","metadata":{"id":"683N0Ji3S6ir"},"source":["# Image Plots"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cBjqKaFJS6is"},"outputs":[],"source":["def plot_example(nrows=6, ncols=4):\n","    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*5, nrows*5))\n","    for r in range(nrows):\n","        for c in range(ncols):\n","            idx = (r * ncols) + c\n","            img = imageio.imread(train['jpeg_bytes'][idx])\n","            image_id = train['id'][idx]\n","            axes[r,c].imshow(img)\n","            axes[r,c].set_title(f'{image_id} | shape: {img.shape}')\n","\n","    plt.show()\n","\n","plot_example()"]},{"cell_type":"markdown","metadata":{"id":"ZfGSgSdKS6is"},"source":["# Labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uEFbSmosS6is"},"outputs":[],"source":["# Labels Meta Data\n","target_name_meta = pd.read_csv('/content/drive/MyDrive/target_name_meta.tsv', delimiter='\\t')\n","target_name_meta['trait_ID'] = target_name_meta['trait_ID'] + '_mean'\n","target_name_meta = target_name_meta.set_index('trait_ID').squeeze().to_dict()\n","\n","display(pd.Series(target_name_meta).to_frame())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k8JvqDq8S6is"},"outputs":[],"source":["# Percentiles of features to use\n","percentiles = [\n","    0.001, 0.01,0.05,0.10,0.25,\n","    0.50,\n","    0.75,0.90,0.95,0.99, 0.999,\n","]\n","labels_describe_df = pd.DataFrame()\n","for target in CONFIG.TARGET_COLUMNS:\n","    labels_describe_df = pd.concat((\n","        labels_describe_df,\n","        train[target].describe(percentiles=percentiles).round(3)\n","    ), axis=1)\n","\n","# Transpose DataFrame\n","labels_describe_df = labels_describe_df.T\n","\n","# Minimum/Maximum Values\n","labels_describe_df.insert(4, 'v_min', CONFIG.V_MIN)\n","labels_describe_df.insert(16, 'v_max', CONFIG.V_MAX)\n","\n","display(labels_describe_df)"]},{"cell_type":"markdown","metadata":{"id":"PfZWBd3QS6is"},"source":["# Plot outliers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q6flpFAhS6is"},"outputs":[],"source":["def plot_samples(target, df, n):\n","    rows = train0.sort_values(target, ascending=False).head(n)\n","    fig, axes = plt.subplots(1, n, figsize=(5*n, 5))\n","    plt.suptitle(f'{target} | {target_name_meta[target]}', size=24)\n","    for ax, (row_idx, row) in zip(axes, rows.iterrows()):\n","        ax.set_title(f'ID: {row.id}, {target}: {row[target]}', size=12)\n","        ax.imshow(imageio.imread(row['jpeg_bytes']))\n","        ax.axis('off')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8PDYmSYYS6is"},"outputs":[],"source":["# As can be observer, whatever unit is used, the outliers are comically large\n","for target in CONFIG.TARGET_COLUMNS:\n","    plot_samples(target, train0, 5)"]},{"cell_type":"markdown","metadata":{"id":"Dw7KjtwZS6is"},"source":["# Filter Outliers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eh5687SpS6is"},"outputs":[],"source":["# Mask to exclude values outside of 0.1% - 99.9% range\n","def get_mask(df):\n","    lower = []\n","    higher = []\n","    mask = np.empty(shape=df[CONFIG.TARGET_COLUMNS].shape, dtype=bool)\n","    # Fill mask based on minimum/maximum values of sample submission\n","    for idx, (t, v_min, v_max) in enumerate(zip(CONFIG.TARGET_COLUMNS, CONFIG.V_MIN, CONFIG.V_MAX)):\n","        labels = df[t].values\n","        mask[:,idx] = ((labels > v_min) & (labels < v_max))\n","    return mask.min(axis=1)\n","\n","# Masks\n","CONFIG.MASK_TRAIN = get_mask(train)\n","CONFIG.MASK_VAL = get_mask(val)\n","# Masked DataFrames\n","train_mask = train[CONFIG.MASK_TRAIN].reset_index(drop=True)\n","val_mask = val[CONFIG.MASK_VAL].reset_index(drop=True)\n","# Add Number Of Steps\n","CONFIG.N_TRAIN_SAMPLES = len(train_mask)\n","CONFIG.N_VAL_SAMPLES = len(val_mask)\n","CONFIG.N_STEPS_PER_EPOCH = (CONFIG.N_TRAIN_SAMPLES // CONFIG.BATCH_SIZE)\n","CONFIG.N_VAL_STEPS_PER_EPOCH = math.ceil(CONFIG.N_VAL_SAMPLES / CONFIG.BATCH_SIZE_VAL)\n","CONFIG.N_STEPS = CONFIG.N_STEPS_PER_EPOCH * CONFIG.N_EPOCHS + 1\n","\n","for m, subset in zip([CONFIG.MASK_TRAIN, CONFIG.MASK_VAL], ['train', 'val']):\n","    print(f'===== {subset} shape: {m.shape} =====')\n","    print(f'{subset} \\t| # Masked Samples: {(1-m.mean())*CONFIG.N_TRAIN_SAMPLES:.0f}')\n","    print(f'{subset} \\t| % Masked Samples: {100-m.mean()*100:.3f}%')"]},{"cell_type":"markdown","metadata":{"id":"3J2snsVyS6is"},"source":["# Label Normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"93wGNbqES6is"},"outputs":[],"source":["# Log Scale Features\n","LOG_FEATURES = ['X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qd6ovKx_S6is"},"outputs":[],"source":["# Fill labels using normalization tool\n","def fill_y(y, df, normalize=False):\n","    for target_idx, target in enumerate(CONFIG.TARGET_COLUMNS):\n","        v = df[target]\n","        if normalize:\n","            # Log10 Transform\n","            if target in LOG_FEATURES:\n","                v = np.log10(v)\n","            # Shift To Have Zero Median\n","            Y_SHIFT[target_idx] = np.mean(v)\n","            v = v - np.median(v)\n","            # Uniform Variance\n","            Y_STD[target_idx] = np.std(v)\n","            v = v / np.std(v)\n","        # Assign to y_train\n","        y[:,target_idx] = v\n","\n","# Feature Scaler\n","Y_SHIFT = np.zeros(CONFIG.N_TARGETS)\n","Y_STD = np.zeros(CONFIG.N_TARGETS)\n","# Masked Labels\n","y_train_mask_raw = np.zeros_like(train_mask[CONFIG.TARGET_COLUMNS], dtype=np.float32)\n","y_train_mask = np.zeros_like(train_mask[CONFIG.TARGET_COLUMNS], dtype=np.float32)\n","y_val_mask = np.zeros_like(val_mask[CONFIG.TARGET_COLUMNS], dtype=np.float32)\n","# Fill Target Arrays\n","fill_y(y_train_mask_raw, train_mask, normalize=False)\n","fill_y(y_train_mask, train_mask, normalize=True)\n","fill_y(y_val_mask, val_mask, normalize=True)\n","# Values\n","display(pd.DataFrame({\n","    'y_shift': Y_SHIFT,\n","    'y_std': Y_STD\n","}, index=CONFIG.TARGET_COLUMNS))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hIrAO7ttS6is"},"outputs":[],"source":["def plot_target_distribution():\n","    fig, axes = plt.subplots(CONFIG.N_TARGETS, 3, figsize=(20, CONFIG.N_TARGETS*4))\n","    v_raw = train[CONFIG.TARGET_COLUMNS].values\n","    for (ax_raw, ax_mask, ax_norm), target, v_r, v_n in zip(axes, CONFIG.TARGET_COLUMNS, v_raw.T, y_train_mask.T):\n","        # Raw\n","        ax_raw.hist(v_r, bins=128)\n","        ax_raw.set_title(f'{target} Raw min: {v_r.min():.3f}, max: {v_r.max():.2e}, µ: {v_r.mean():.2e}, σ: {v_r.std():.2f}', size=10)\n","        # Masked\n","        v_m = v_r[CONFIG.MASK_TRAIN]\n","        ax_mask.hist(v_r, bins=128)\n","        ax_mask.set_title(f'{target} Masked min: {v_m.min():.3f}, max: {v_m.max():.2e}, µ: {v_m.mean():.2e}, σ: {v_m.std():.2f}', size=10)\n","        # Normalized\n","        ax_norm.hist(v_n, bins=128)\n","        ax_norm.set_title(f'{target} Norm min: {v_n.min():.3f}, max: {v_n.max():.2f}, µ: {v_n.mean():.2f}, σ: {v_n.std():.2f}', size=10)\n","    plt.subplots_adjust(hspace=0.25, wspace=0.30)\n","    plt.show()\n","\n","plot_target_distribution()"]},{"cell_type":"markdown","metadata":{"id":"zn3n-t_uS6it"},"source":[" # Features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jWsBKIaKS6it"},"outputs":[],"source":["# Standard Scaler for Features\n","FEATURE_SCALER = StandardScaler()\n","\n","# Fit and transform on training features\n","train_features_mask = FEATURE_SCALER.fit_transform(train_mask[FEATURE_COLUMNS].values.astype(np.float32))\n","# Transform val/test features using scaler fitted on train data\n","val_features_mask = FEATURE_SCALER.transform(val_mask[FEATURE_COLUMNS].values.astype(np.float32))\n","test_features = FEATURE_SCALER.transform(test[FEATURE_COLUMNS].values.astype(np.float32))\n","# Convert Features to Torch Tensors\n","train_features_mask = torch.tensor(train_features_mask)\n","val_features_mask = torch.tensor(val_features_mask)\n","test_features = torch.tensor(test_features)"]},{"cell_type":"markdown","metadata":{"id":"T5Ex0vmnS6it"},"source":["# Transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LuTCTixuS6it"},"outputs":[],"source":["MEAN = np.array([0.485, 0.456, 0.406])\n","STD = np.array([0.229, 0.224, 0.225])\n","# Training Augmentations\n","TRAIN_TRANSFORMS = A.Compose([\n","        A.RandomSizedCrop(\n","            [int(0.85*CONFIG.IMAGE_SIZE0), CONFIG.IMAGE_SIZE0],\n","            CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE, w2h_ratio=1.0, p=1.0\n","        ),\n","        A.HorizontalFlip(p=0.50),\n","        A.RandomBrightnessContrast(brightness_limit=0.10, contrast_limit=0.10, p=0.50),\n","        A.ImageCompression(quality_lower=75, quality_upper=100, p=0.5),\n","        ToTensorV2(),\n","    ])\n","# Test Augmentations\n","VAL_TEST_TRANSFORMS = A.Compose([\n","        A.Resize(CONFIG.IMAGE_SIZE,CONFIG.IMAGE_SIZE),\n","        ToTensorV2(),\n","    ])"]},{"cell_type":"markdown","metadata":{"id":"AfjU1W6CS6it"},"source":["# Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BrSMi5bDS6it"},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, X_jpeg_bytes, y, features, transforms=None):\n","        self.X_jpeg_bytes = X_jpeg_bytes\n","        self.y = y\n","        self.features = features\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.X_jpeg_bytes)\n","\n","    def __getitem__(self, index):\n","        X_sample = {\n","            'image': self.transforms(\n","                    image=imageio.imread(self.X_jpeg_bytes[index]),\n","                )['image'],\n","            'feature': self.features[index],\n","        }\n","        y_sample = self.y[index]\n","\n","        return X_sample, y_sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dBEzLeCoS6it"},"outputs":[],"source":["import psutil\n","from torch.utils.data import DataLoader\n","\n","# Assuming MyDataset is a custom dataset class you've defined elsewhere\n","# and CONFIG, TRAIN_TRANSFORMS, and VAL_TEST_TRANSFORMS are predefined\n","\n","# Set a reasonable number of workers\n","num_workers = max(1, psutil.cpu_count() // 2)\n","\n","# Train DataLoader\n","train_dataset = MyDataset(\n","    train_mask['jpeg_bytes'].values,\n","    y_train_mask,\n","    train_features_mask,\n","    TRAIN_TRANSFORMS,\n",")\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=CONFIG.BATCH_SIZE,\n","    drop_last=True,  # Ensures that all batches have the same size\n","    num_workers=num_workers,  # Adjusted number of workers\n","    pin_memory=True if torch.cuda.is_available() else False  # Pin memory for GPU acceleration\n",")\n","train_dataloader_iter = iter(train_dataloader)\n","\n","# Validation DataLoader\n","val_dataset = MyDataset(\n","    val_mask['jpeg_bytes'].values,\n","    y_val_mask,\n","    val_features_mask,\n","    VAL_TEST_TRANSFORMS,\n",")\n","val_dataloader = DataLoader(\n","    val_dataset,\n","    batch_size=CONFIG.BATCH_SIZE_VAL,\n","    drop_last=False,  # It's okay to have the last batch smaller in validation\n","    num_workers=num_workers,  # Consistent number of workers\n","    pin_memory=True if torch.cuda.is_available() else False\n",")\n","\n","# Test DataLoader\n","test_dataset = MyDataset(\n","    test['jpeg_bytes'].values,\n","    test['id'].values,\n","    test_features,\n","    VAL_TEST_TRANSFORMS,\n",")\n","test_dataloader = DataLoader(\n","    test_dataset,\n","    batch_size=CONFIG.BATCH_SIZE_VAL,  # Typically, the batch size could be the same as for validation\n","    drop_last=False,  # Similar to validation\n","    num_workers=num_workers,\n","    pin_memory=True if torch.cuda.is_available() else False\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"kLyk5aLXS6it"},"source":["import time\n","from tqdm import tqdm\n","\n","# Benchmark Dataset\n","N = 10\n","t_start = time.perf_counter_ns()\n","\n","# Reset the iterator to ensure we are measuring the same workload each time\n","train_dataloader_iter = iter(train_dataloader)\n","\n","try:\n","    for _ in tqdm(range(N), desc=\"Measuring DataLoader Throughput\"):\n","        next(train_dataloader_iter)\n","except StopIteration:\n","    print(\"Reached the end of the dataset before expected.\")\n","\n","n_images_per_second = (N * CONFIG.BATCH_SIZE) / ((time.perf_counter_ns() - t_start) * 1e-9)  # corrected time unit conversion\n","print(f'# Images/Second: {n_images_per_second:.0f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lQYm2IiOS6iu"},"outputs":[],"source":["# Example batch\n","X_batch, y_batch = next(train_dataloader_iter)\n","for k, v in X_batch.items():\n","    print(f'X_batch {k} shape: {v.shape}, dtype: {v.dtype}')\n","    print(f'X_batch {k} min: {v.min():.3f}, max: {v.max():.3f}')\n","    print(f'X_batch {k} µ: {v.float().mean():.3f}, σ: {v.float().std():.3f}')\n","# Label\n","print(f'y_batch shape: {y_batch.shape}, dtype: {y_batch.dtype}')\n","print(f'y_batch min: {y_batch.min():.3f}, max: {y_batch.max():.3f}')\n","print(f'y_batch µ: {y_batch.mean():.3f}, σ: {y_batch.std():.3f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rUyG6VW4S6iu"},"outputs":[],"source":["def plot_batch(nrows=6, ncols=4):\n","    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*5, nrows*5))\n","    for r in range(nrows):\n","        for c in range(ncols):\n","            idx = (r * ncols) + c\n","            # Put image on CPU\n","            img = X_batch['image'][idx].swapaxes(0,2).detach().cpu().numpy()\n","            # Denormalize Image\n","            image_id = train['id'][idx]\n","            axes[r,c].imshow(img)\n","            axes[r,c].set_title(f'{image_id} | shape: {img.shape}')\n","\n","    plt.show()\n","\n","plot_batch()"]},{"cell_type":"markdown","metadata":{"id":"vOmRIkcJS6iu"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qmbVwoZoS6iu"},"outputs":[],"source":["def search_timm_model(query):\n","    search_result = [n for n in timm.list_models(pretrained=True) if query in n]\n","    for i, name in enumerate(search_result):\n","        print(f'{i:02d} | {name}')\n","\n","search_timm_model('efficientvit')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rqR-GJSBS6iu"},"outputs":[],"source":["# Count model parameters\n","def count_parameters(model):\n","    return sum([p.numel() for p in model.parameters()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T3kq__yZS6iu"},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # ImageNet Normalize Input\n","        self.normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","\n","        # Backbone\n","        self.backbone = timm.create_model(\n","                'efficientvit_b1.r288_in1k',\n","                pretrained=True,\n","                num_classes=0,\n","            )\n","\n","        # Features\n","        self.features = nn.Sequential(\n","            nn.Linear(CONFIG.N_FEATURES,256),\n","            nn.GELU(),\n","            nn.Linear(256,256),\n","        )\n","\n","        # Label\n","        self.label = nn.Sequential(\n","            nn.Linear(256,256),\n","            nn.GELU(),\n","            nn.Linear(256,CONFIG.N_TARGETS, bias=False),\n","        )\n","\n","        # Initialize Weights\n","        self.initialize_weights()\n","\n","    def initialize_weights(self):\n","        # Features\n","        nn.init.kaiming_uniform_(self.features[2].weight)\n","        # Label\n","        nn.init.zeros_(self.label[2].weight)\n","\n","    def forward(self, inputs, debug=False):\n","        if debug:\n","            embedding = self.backbone(self.normalize(inputs['image'].float() / 255))\n","            features = self.features(inputs['feature'])\n","            label = self.label(embedding + features)\n","            return {\n","                'features': features,\n","                'embedding': embedding,\n","                'label': label,\n","            }\n","        else:\n","            return {\n","                'label': self.label(\n","                    self.backbone(self.normalize(inputs['image'].float() / 255)) + self.features(inputs['feature'])\n","                )\n","            }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wNikwq-lS6iu"},"outputs":[],"source":["# Clear torch cache\n","torch.cuda.empty_cache()\n","\n","# Load Weights if model is not trained\n","if not CONFIG.TRAIN_MODEL:\n","    model = torch.load('/kaggle/input/planttraits2024-eda-dataset/model.pth')\n","else:\n","    # Create new Model\n","    model = Model()\n","\n","# Model to GPU memory\n","model = model.to('cuda')\n","\n","print(f'# Model Parameters: {count_parameters(model):,}')\n","\n","with torch.no_grad():\n","    # Put inputs on GPU\n","    for k, v in X_batch.items():\n","        X_batch[k] = v.to('cuda')\n","    outputs = model(X_batch, debug=True)\n","    for k, v in outputs.items():\n","        print(f'outputs {k} shape: {v.shape}, min: {v.min():.3f}, max: {v.max():.3f}, µ: {v.mean():.3f}, σ: {v.std():.3f}')\n","    # Label Outputs\n","    for o in outputs['label'][:3,:]:\n","        print(o.detach().cpu().numpy().tolist())"]},{"cell_type":"markdown","metadata":{"id":"UvcvRdhgS6iu"},"source":["# Learning Rate Schedule"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crW6qeKHS6iu"},"outputs":[],"source":["# Get the learning rate scheduler\n","def get_lr_scheduler(optimizer):\n","    return torch.optim.lr_scheduler.OneCycleLR(\n","        optimizer=optimizer,\n","        max_lr=CONFIG.LR_MAX,\n","        total_steps=CONFIG.N_STEPS,\n","        pct_start=0.10,\n","        anneal_strategy='cos',\n","        div_factor=1e3,\n","        final_div_factor=1e4,\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3XhebP6dS6iu"},"outputs":[],"source":["# Plot Learning Rate Scheduler\n","def plot_lr_scheduler():\n","    lr_scheduler = get_lr_scheduler(torch.optim.Adam(model.parameters()))\n","    lrs  = []\n","    for step in range(CONFIG.N_STEPS):\n","        lrs.append(lr_scheduler.get_last_lr())\n","        lr_scheduler.step()\n","    # Plot Learning Rate\n","    plt.figure(figsize=(12,5))\n","    plt.title('Learning Rate Schedule')\n","    plt.xlim(0, CONFIG.N_STEPS)\n","    plt.ylim(0, CONFIG.LR_MAX*1.1)\n","    plt.xlabel('Step')\n","    plt.ylabel('Learning Rate')\n","    plt.plot(lrs)\n","    plt.grid()\n","    plt.show()\n","    # Reset Learning Rate Scheduler\n","    lr_scheduler._step_count = 0\n","    lr_scheduler.last_epoch = 0\n","\n","plot_lr_scheduler()"]},{"cell_type":"markdown","metadata":{"id":"wIaR2p34S6iv"},"source":["# Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v6u9LHk8S6iv"},"outputs":[],"source":["# Average meter to keep track of metrics/loss during training\n","class AverageMeter(object):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val):\n","        self.sum += val.sum()\n","        self.count += val.numel()\n","        # Average is simply the sum divided by the count\n","        self.avg = self.sum / self.count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kwYA7zhoS6iv"},"outputs":[],"source":["# Average meter to keep track of metrics/loss during training\n","class R2_METRIC(object):\n","    def __init__(self):\n","        self.reset()\n","        self.y_mean = torch.tensor(train0[CONFIG.TARGET_COLUMNS].median(axis=0).values).to('cuda')\n","\n","    def reset(self):\n","        self.avg = torch.zeros(CONFIG.N_TARGETS).to('cuda')\n","        self.rss = torch.zeros(CONFIG.N_TARGETS).to('cuda')\n","        self.tss = torch.zeros(CONFIG.N_TARGETS).to('cuda')\n","\n","    def update(self, y_pred, y_true, mean=False):\n","        self.rss += torch.sum((y_true - y_pred)**2, dim=0)\n","        self.tss += torch.sum((y_true - self.y_mean)**2, dim=0)\n","        self.avg = 1 - (self.rss / torch.maximum(self.tss, CONFIG.EPS_CUDA))"]},{"cell_type":"markdown","metadata":{"id":"sc0agpQWS6iv"},"source":["# Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RtoH4FTHS6iv"},"outputs":[],"source":["# Y_SHIFT As Torch Tensor On GPU\n","Y_SHIFT_CUDA = torch.tensor(Y_SHIFT).to('cuda')\n","Y_STD_CUDA = torch.tensor(Y_STD).to('cuda')\n","# Is Log Feature Flag\n","IS_LOG_FEATURE = torch.tensor(np.isin(CONFIG.TARGET_COLUMNS, LOG_FEATURES)).to('cuda')\n","\n","def denormalize(y_pred, y_true=None):\n","    # Scale Back\n","    y_pred = (y_pred * Y_STD_CUDA) + Y_SHIFT_CUDA\n","    # Log Scale\n","    y_pred = torch.where(IS_LOG_FEATURE, 10**y_pred, y_pred)\n","    # Optionally Denormalize y_true\n","    if y_true is not None:\n","        y_true = (y_true * Y_STD_CUDA) + Y_SHIFT_CUDA\n","        y_true = torch.where(IS_LOG_FEATURE, 10**y_true, y_true)\n","        return y_pred, y_true\n","    else:\n","        return y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JVuQMVRNS6iv"},"outputs":[],"source":["# Mean feature values used to compute R2 loss\n","Y_MEDIAN = torch.tensor(CONFIG.TARGET_MEDIANS).to('cuda')\n","# Total Variation\n","MEAN_VARIATION = torch.tensor(\n","        (CONFIG.TARGET_MEDIANS - y_train_mask_raw)\n","    ).abs().mean(dim=0).to('cuda')\n","# R2 Loss\n","def r2_loss_fn(y_pred, y_true):\n","    B = len(y_pred)\n","    # Compute column wise sum of residuals and totals\n","    ss_res = (y_true - y_pred)**2\n","    ss_total = (y_true - Y_MEDIAN)**2\n","    # r2 ranging from 0 to infinity\n","    loss = torch.sum(ss_res, dim=0) / torch.maximum(torch.sum(ss_total, dim=0), CONFIG.EPS_CUDA)\n","    # Return Mean Of Loss\n","    return torch.mean(loss)\n","\n","r2_loss_fn(denormalize(outputs['label']), denormalize(y_batch.to('cuda')))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EjU1bXHlS6iv"},"outputs":[],"source":["def validation_step():\n","    # Loss Function\n","    R2_LOSS_FN = r2_loss_fn\n","    # Put model in evaluation mode\n","    model.eval()\n","    # Metrics Trackers\n","    R2 = R2_METRIC()\n","    R2_LOSS = AverageMeter()\n","    # Iterave Over Validation Set\n","    for step, (X_sample, y_true) in enumerate(val_dataloader):\n","        y_true = y_true.to('cuda')\n","        # Put label on GPU\n","        with torch.no_grad():\n","            for k, v in X_sample.items():\n","                X_sample[k] = v.to('cuda')\n","            # Forward Pass\n","            y_pred = model(X_sample)['label']\n","        # Denormalize\n","        y_pred_raw, y_true_raw = denormalize(y_pred, y_true)\n","        # Loss\n","        r2_loss = R2_LOSS_FN(y_pred_raw, y_true_raw)\n","        # Update Loss Metrics\n","        R2_LOSS.update(r2_loss)\n","        # Update Metrics\n","        R2.update(y_pred_raw, y_true_raw)\n","        # Logs\n","        r2_str = \", \".join(\n","            [f\"{f}: {v:+.3f}\" for f, v in zip(CONFIG.TARGET_COLUMNS_TEST, R2.avg)\n","        ])\n","        if not CONFIG.IS_INTERACTIVE and (step + 1) == CONFIG.N_VAL_STEPS_PER_EPOCH:\n","            print(\n","                f'VAL | R2 loss: {R2_LOSS.avg:.4f}, R2: {R2.avg.mean():.3f}, {r2_str}' + (' ' * 10)\n","            )\n","        elif CONFIG.IS_INTERACTIVE:\n","            print(\n","                f'\\rVAL {step+1:02d}/{CONFIG.N_VAL_STEPS_PER_EPOCH} | R2 loss: {R2_LOSS.avg:.4f}, ' +\n","                f'R2: {R2.avg.mean():.3f}, {r2_str}' + (' ' * 10),\n","                end='\\n' if (step + 1) == CONFIG.N_VAL_STEPS_PER_EPOCH else '', flush=True,\n","            )\n","\n","validation_step()"]},{"cell_type":"markdown","metadata":{"id":"UuJOqqo4S6iv"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"10nM3GDbS6iv"},"outputs":[],"source":["# Loss\n","R2_LOSS_FN = r2_loss_fn\n","# Optimizer\n","optimizer = torch.optim.AdamW(\n","    params=model.parameters(),\n","    lr=CONFIG.LR_MAX,\n","    weight_decay=CONFIG.WEIGHT_DECAY,\n",")\n","# Learning Rate Scheduler\n","LR_SCHEDULER = get_lr_scheduler(optimizer)\n","# Metrics Trackers\n","R2 = R2_METRIC()\n","R2_LOSS = AverageMeter()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wXjqDnZlS6iv"},"outputs":[],"source":["if CONFIG.TRAIN_MODEL:\n","    for epoch in range(CONFIG.N_EPOCHS):\n","        # Reset Metrics\n","        R2.reset()\n","        R2_LOSS.reset()\n","        # Put model in training mode\n","        model.train()\n","        # Iterate Over Training Dataloader\n","        for step, (X_batch, y_true) in enumerate(train_dataloader):\n","            # Put batch on GPU\n","            for k, v in X_batch.items():\n","                X_batch[k] = v.to('cuda')\n","            y_true = y_true.to('cuda')\n","            # Step Time\n","            t_start = time.perf_counter_ns()\n","            # Forward Pass\n","            y_pred = model(X_batch)['label']\n","            # Denormalize\n","            y_pred_raw, y_true_raw = denormalize(y_pred, y_true)\n","            # Loss\n","            r2_loss = R2_LOSS_FN(y_pred_raw, y_true_raw)\n","            # Update Loss Metrics\n","            R2_LOSS.update(r2_loss)\n","            # Compute Gradients\n","            r2_loss.backward()\n","            # Backward Pass\n","            optimizer.step()\n","            # Zero Out Gradients\n","            optimizer.zero_grad()\n","            # Update Metrics\n","            R2.update(y_pred_raw, y_true_raw)\n","            # Compute R2 Metrics String\n","            r2_str = \", \".join([\n","                f\"{f}: {v:+.3f}\" for f, v in zip(CONFIG.TARGET_COLUMNS_TEST, R2.avg)\n","            ])\n","            # Logs\n","            if not CONFIG.IS_INTERACTIVE and (step + 1) == CONFIG.N_STEPS_PER_EPOCH:\n","                print(\n","                    f'EPOCH {epoch+1:02d} {step+1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' +\n","                    f'R2 loss: {R2_LOSS.avg:.4f}, R2: {R2.avg.mean():+.3f}, {r2_str}, ' +\n","                    f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n","                )\n","            elif CONFIG.IS_INTERACTIVE:\n","                print(\n","                    f'\\rEPOCH {epoch+1:02d} {step+1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' +\n","                    f'R2 loss: {R2_LOSS.avg:.4f}, R2: {R2.avg.mean():+.3f}, {r2_str}, ' +\n","                    f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n","                    end='\\n' if (step + 1) == CONFIG.N_STEPS_PER_EPOCH else '', flush=True,\n","                )\n","            # Learning Rate Scheduler Step\n","            LR_SCHEDULER.step()\n","        # Validation Step\n","        validation_step()\n","\n","# Save entire model object\n","torch.save(model, 'model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U5o9KnQbS6iv"},"outputs":[],"source":["# Save entire model object\n","torch.save(model, 'model.pth')"]},{"cell_type":"markdown","metadata":{"id":"2xy7oZMGS6iv"},"source":["# Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5XhaWFcYS6iv"},"outputs":[],"source":["# Minimum And Maximum Values To Clip Predictions\n","TARGET_MIN = train0[CONFIG.TARGET_COLUMNS].values.min(axis=0)\n","TARGET_MAX = train0[CONFIG.TARGET_COLUMNS].values.max(axis=0)\n","# Submission Rows\n","SUBMISSION_ROWS = []\n","# Put Model in Evaluation Mode\n","model.eval()\n","for i, (X_sample_test, test_id) in enumerate(tqdm(test_dataset)):\n","    # Only 100 predictions in interactive mode\n","    if CONFIG.IS_INTERACTIVE and i == 100:\n","        break\n","    # Put sample on GPU and add batch dimension\n","    for k, v in X_sample_test.items():\n","        X_sample_test[k] = v.to('cuda').unsqueeze(0)\n","    # Prediction without gradients\n","    with torch.no_grad():\n","        y_pred = model(X_sample_test)['label']\n","    # Reverse Scaling\n","    y_pred, _ = denormalize(y_pred, y_pred)\n","    y_pred = y_pred.detach().cpu().numpy().squeeze()\n","    # Clip Values\n","    y_pred = np.clip(y_pred, TARGET_MIN, TARGET_MAX)\n","    # Add To Rows\n","    row = { 'id': test_id }\n","    # Add Predictions column by column\n","    for k, v in zip(CONFIG.TARGET_COLUMNS, y_pred):\n","        # Remove \"_mean\" part of target column\n","        row[k.replace('_mean', '')] = v\n","    # Add To Submission Rows\n","    SUBMISSION_ROWS.append(row)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E5fk5X2vS6iw"},"outputs":[],"source":["# Make Submission CSV\n","submission_df = pd.DataFrame(SUBMISSION_ROWS)\n","\n","display(submission_df.head(30))\n","\n","# Make\n","submission_df.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SpAKz9MXS6iw"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZxHp5OOwS6iw"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9I-uxa1GS6iw"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YCAJhp0SS6iw"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CpiDgdDpS6iw"},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":8046133,"sourceId":65626,"sourceType":"competition"},{"datasetId":4468693,"sourceId":8108731,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f39a07b5909349078ef9f32b62603973":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6dc36e4f7524cbc9fcf7f0e65bec227","IPY_MODEL_1485ddcecf2f4aacb026b0def6901589","IPY_MODEL_deafdc1b0cfc43ef9807cd48e64aa524"],"layout":"IPY_MODEL_1430c059eb1c459bb7a3cbd7e21bd2b3","tabbable":null,"tooltip":null}},"f6dc36e4f7524cbc9fcf7f0e65bec227":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_5f1e37e804cb4ad8ae7e606fd0b6f55c","placeholder":"​","style":"IPY_MODEL_c98318f60963493f86286e7e42f427c6","tabbable":null,"tooltip":null,"value":"  0%"}},"1485ddcecf2f4aacb026b0def6901589":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_allow_html":false,"layout":"IPY_MODEL_ec8a33b0aefd4b509545460098351058","max":55489,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d6f0f33b02b6477099b1944b8ec998e3","tabbable":null,"tooltip":null,"value":1}},"deafdc1b0cfc43ef9807cd48e64aa524":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_bba9ab2a59884be887fc8c187864e1f2","placeholder":"​","style":"IPY_MODEL_c1e3168f3e884f95b10d924236222e50","tabbable":null,"tooltip":null,"value":" 1/55489 [00:00&lt;14:51, 62.21it/s]"}},"1430c059eb1c459bb7a3cbd7e21bd2b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f1e37e804cb4ad8ae7e606fd0b6f55c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c98318f60963493f86286e7e42f427c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"ec8a33b0aefd4b509545460098351058":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6f0f33b02b6477099b1944b8ec998e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bba9ab2a59884be887fc8c187864e1f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1e3168f3e884f95b10d924236222e50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}}}}},"nbformat":4,"nbformat_minor":0}